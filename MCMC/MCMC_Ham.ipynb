{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting camb\n",
      "  Using cached camb-1.5.4.tar.gz (1.8 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from camb) (1.13.0)\n",
      "Collecting sympy>=1.0 (from camb)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from camb) (24.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from scipy>=1.0->camb) (1.26.4)\n",
      "Collecting mpmath>=0.19 (from sympy>=1.0->camb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Building wheels for collected packages: camb\n",
      "  Building wheel for camb (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for camb: filename=camb-1.5.4-py3-none-any.whl size=1988431 sha256=c211735372ee4128c9824c81677d4b83d3ceafc0aea9aef7a116491726c18335\n",
      "  Stored in directory: /Users/henrybae/Library/Caches/pip/wheels/e6/bd/75/17f7c98e7f88328a18c8cec889e391f5eb5be8c7258a9b9783\n",
      "Successfully built camb\n",
      "Installing collected packages: mpmath, sympy, camb\n",
      "Successfully installed camb-1.5.4 mpmath-1.3.0 sympy-1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install camb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[982.32562024 927.57538209 875.41964977 ...  36.22063115  36.11447954\n",
      "  36.00921749]\n",
      "[ 2.75474425  3.09469103  2.90353789 ... -1.26516941 -1.27129668\n",
      " -1.27752765]\n",
      "[0.03586869 0.04609061 0.04003475 ... 1.56565523 1.56519372 1.56468134]\n"
     ]
    }
   ],
   "source": [
    "import camb\n",
    "import numpy as np\n",
    "import os\n",
    "import likelihood\n",
    "\n",
    "def calculate_power_spectra(params, lensed=True):\n",
    "    # Set up a new set of parameters for CAMB\n",
    "    pars = camb.set_params(**params)\n",
    "    # Calculate results for these parameters\n",
    "    results = camb.get_results(pars)\n",
    "    # Get dictionary of CAMB power spectra\n",
    "    powers = results.get_cmb_power_spectra(pars, CMB_unit='muK')\n",
    "    # Choose the appropriate power spectrum\n",
    "    if lensed:\n",
    "        cl = powers['total']\n",
    "    else:\n",
    "        cl = powers['unlensed_scalar']\n",
    "    # Cut out the first 2 elements of the power spectra, which are zero\n",
    "    cl_cut = cl[2:]\n",
    "    # Get the TT, TE, and EE power spectra\n",
    "    cl_tt = cl_cut[:, 0]\n",
    "    cl_te = cl_cut[:, 3]\n",
    "    cl_ee = cl_cut[:, 1]\n",
    "    return cl_tt, cl_te, cl_ee\n",
    "\n",
    "params = {\n",
    "    # Parameters that are part of the proposal distribution:\n",
    "    'ombh2': 0.025,                # Baryon density parameter\n",
    "    'omch2': 0.122,                # Cold dark matter density parameter\n",
    "    'cosmomc_theta': 1.04109/100,       # Theta_MC - need to be transformed\n",
    "    'tau': 0.06,                   # Optical depth to reionization\n",
    "    'ns': 0.965,                   # Scalar spectral index\n",
    "    'As': 2.0e-9,# the scalar amplitude, need to be transformed for proposal distribution\n",
    "\n",
    "    # Fixed parameters:\n",
    "    #'H0': 69.5,                    # Hubble constant in km/s/Mpc (Fixed)\n",
    "    'mnu': 0.06,                   # Sum of neutrino masses in eV (Fixed)\n",
    "    'omk': 0,                      # Curvature density parameter, flat universe (Fixed)\n",
    "    'halofit_version': 'mead',     # Non-linear matter power spectrum model version (Fixed)\n",
    "    'lmax': 2800                   # Maximum multipole number for calculations (Fixed)\n",
    "}\n",
    "\n",
    "likelihood_function = likelihood.PlanckLitePy(spectra='TT')\n",
    "\n",
    "cl_tt, cl_te, cl_ee = calculate_power_spectra(params, lensed=True)\n",
    "print(cl_tt)\n",
    "print(cl_te)\n",
    "print(cl_ee)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_params_and_calculate_spectra(array):\n",
    "    array = array.copy()  # Create a copy of the array\n",
    "    # Modify the third and sixth elements of the array\n",
    "    array[2] /= 100\n",
    "    array[5] = np.exp(array[5]) / 1e10\n",
    "\n",
    "    # Set the parameters for the proposal distribution\n",
    "    params = {\n",
    "        'ombh2': array[0],\n",
    "        'omch2': array[1],\n",
    "        'cosmomc_theta': array[2],\n",
    "        'tau': array[3],\n",
    "        'ns': array[4],\n",
    "        'As': array[5],\n",
    " \n",
    "        \n",
    "        'mnu': 0.06,\n",
    "        'omk': 0,\n",
    "        'halofit_version': 'mead',\n",
    "        'lmax': 2800\n",
    "    }\n",
    "\n",
    "    # Call the calculate_power_spectra function and return the result\n",
    "    return calculate_power_spectra(params)\n",
    "\n",
    "\n",
    "def likelihoodfunc(array):\n",
    "    cl_tt, cl_te, cl_ee = process_params_and_calculate_spectra(array)\n",
    "    return likelihood_function.loglike(cl_tt, cl_te, cl_ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_distribution(current_state):\n",
    "    step_sizes = np.array([\n",
    "        np.sqrt(0.0001**2),  # ombh2\n",
    "        np.sqrt(0.001**2),   # omch2\n",
    "        np.sqrt(0.0004**2),  # theta_MC_100\n",
    "        np.sqrt(0.006**2),   # tau\n",
    "        np.sqrt(0.004**2),   # ns\n",
    "        np.sqrt(0.001**2)    # log(10^10 As)\n",
    "    ])\n",
    "    proposal_step = np.random.normal(0, step_sizes)\n",
    "    return current_state + proposal_step\n",
    "\n",
    "\n",
    "\n",
    "def proposal_distribution_2(current_state):\n",
    "    step_sizes = np.array([\n",
    "        np.sqrt(0.001**2),  # ombh2\n",
    "        np.sqrt(0.001**2),   # omch2\n",
    "        np.sqrt(0.0004**2),  # theta_MC_100\n",
    "        np.sqrt(0.006**2),   # tau\n",
    "        np.sqrt(0.004**2),   # ns\n",
    "        np.sqrt(0.01**2)    # log(10^10 As)\n",
    "    ])\n",
    "    proposal_step = np.random.normal(0, step_sizes)\n",
    "    return current_state + proposal_step\n",
    "\n",
    "def proposal_distribution_3(current_state):\n",
    "    step_sizes = np.array([\n",
    "        0.0001,  # ombh2\n",
    "        0.0005,  # omch2\n",
    "        0.0002,  # theta_MC_100\n",
    "        0.003,   # tau\n",
    "        0.002,   # ns\n",
    "        0.001    # log(10^10 As)\n",
    "    ])\n",
    "    proposal_step = np.random.normal(0, step_sizes)\n",
    "    return current_state + proposal_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lenstools\n",
      "  Downloading lenstools-1.2.tar.gz (259 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.6/259.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from lenstools) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from lenstools) (1.12.0)\n",
      "Requirement already satisfied: pandas in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from lenstools) (2.2.1)\n",
      "Requirement already satisfied: matplotlib in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from lenstools) (3.8.3)\n",
      "Requirement already satisfied: astropy in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from lenstools) (6.0.1)\n",
      "Collecting emcee<=2.2.1 (from lenstools)\n",
      "  Downloading emcee-2.2.1.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyerfa>=2.0.1.1 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from astropy->lenstools) (2.0.1.4)\n",
      "Requirement already satisfied: astropy-iers-data>=0.2024.2.26.0.28.55 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from astropy->lenstools) (0.2024.4.8.0.32.4)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from astropy->lenstools) (6.0.1)\n",
      "Requirement already satisfied: packaging>=19.0 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from astropy->lenstools) (24.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from matplotlib->lenstools) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from pandas->lenstools) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from pandas->lenstools) (2024.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->lenstools) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->lenstools) (1.16.0)\n",
      "Building wheels for collected packages: lenstools, emcee\n",
      "  Building wheel for lenstools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lenstools: filename=lenstools-1.2-cp39-cp39-macosx_14_0_arm64.whl size=314462 sha256=9979540fe3153a8a46c339590cf9bdfd80b7958b8a5961a518d57b6b11e92f82\n",
      "  Stored in directory: /Users/henrybae/Library/Caches/pip/wheels/01/fd/7a/bcad0ec1952249ea1549ff746c73e14bd9f086a63dc58ccaa4\n",
      "  Building wheel for emcee (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emcee: filename=emcee-2.2.1-py3-none-any.whl size=29592 sha256=f745a076abee92ff9ce27e08ad19dc52bce27a8904c960a2641df7aa256afa81\n",
      "  Stored in directory: /Users/henrybae/Library/Caches/pip/wheels/a2/78/08/02ba0bb42f9b3ce7538ba285b8027b261cffa4414d55c5267d\n",
      "Successfully built lenstools emcee\n",
      "Installing collected packages: emcee, lenstools\n",
      "Successfully installed emcee-2.2.1 lenstools-1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lenstools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 23:23:28.726091: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-04-17 23:23:28.726119: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-04-17 23:23:28.726124: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-04-17 23:23:28.726283: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-17 23:23:28.726299: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "va = 1.0\n",
    "priors = [\n",
    "    tfd.Normal(loc=0.0224, scale=tf.sqrt(va)*0.0001),  # ombh2\n",
    "    tfd.Normal(loc=0.12, scale=tf.sqrt(va)*0.001),  # omch2\n",
    "    tfd.Normal(loc=1.04109, scale=tf.sqrt(va)*0.0004),  # theta_MC_100\n",
    "    tfd.Normal(loc=0.055, scale=tf.sqrt(va)*0.006),  # tau\n",
    "    tfd.Normal(loc=0.965, scale=tf.sqrt(va)*0.004),  # ns\n",
    "    tfd.Normal(loc=3.05, scale=tf.sqrt(va)*0.001)  # log(10^10 As)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_distribution_3(current_state):\n",
    "    step_sizes = np.array([\n",
    "        0.0001,  # ombh2\n",
    "        0.0005,  # omch2\n",
    "        0.0002,  # theta_MC_100\n",
    "        0.003,   # tau\n",
    "        0.002,   # ns\n",
    "        0.001    # log(10^10 As)\n",
    "    ])\n",
    "    current_state = np.stack(current_state, axis=0)  # Convert list of tensors to a tensor\n",
    "    num_chains = current_state.shape[1]\n",
    "    proposal_step = np.random.normal(0, step_sizes[:, None], size=(6, num_chains))\n",
    "    return current_state + proposal_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMC_HMC:\n",
    "    def __init__(self, likelihood_function, priors, num_samples, num_chains, step_size=0.1, num_burnin_steps=1000):\n",
    "        self.likelihood_function = likelihood_function\n",
    "        self.priors = priors\n",
    "        self.num_samples = num_samples\n",
    "        self.num_chains = num_chains\n",
    "        self.step_size = step_size\n",
    "        self.num_burnin_steps = num_burnin_steps\n",
    "\n",
    "        # Define the HMC kernel with adaptive step size\n",
    "        self.kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "            tfp.mcmc.HamiltonianMonteCarlo(\n",
    "                target_log_prob_fn=self.joint_log_prob,\n",
    "                num_leapfrog_steps=3,\n",
    "                step_size=self.step_size,\n",
    "                state_gradients_are_stopped=True),\n",
    "            num_adaptation_steps=int(num_burnin_steps * 0.8))\n",
    "\n",
    "    def joint_log_prob(self, *params):\n",
    "        \"\"\"Calculate the joint log probability of model and priors.\"\"\"\n",
    "        params = tf.concat(params, axis=0)  # Concatenate the parameters into a single array\n",
    "        prior_log_prob = sum(prior.log_prob(param) for prior, param in zip(self.priors, params))\n",
    "        likelihood_log_prob = self.likelihood_function(*params)\n",
    "        return prior_log_prob + likelihood_log_prob\n",
    "\n",
    "    def run_chain(self):\n",
    "        # Initial state by sampling from the proposal distribution\n",
    "        init_state = proposal_distribution_3([prior.sample([self.num_chains]) for prior in self.priors])\n",
    "\n",
    "        # Convert list of states into a tuple of states needed for TFP\n",
    "        init_state = tuple(init_state)\n",
    "\n",
    "        # Running the MCMC chain\n",
    "        samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "            num_results=self.num_samples,\n",
    "            num_burnin_steps=self.num_burnin_steps,\n",
    "            current_state=init_state,\n",
    "            kernel=self.kernel,\n",
    "            trace_fn=lambda _, pkr: pkr.inner_results.is_accepted)\n",
    "\n",
    "        return samples, tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32))\n",
    "\n",
    "    def sample(self):\n",
    "        samples, acceptance_rate = self.run_chain()\n",
    "        print(f'Acceptance rate: {acceptance_rate.numpy()}')\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`x` and `y` must have the same dtype, got tf.float64 != tf.float32.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mcmc \u001b[38;5;241m=\u001b[39m MCMC_HMC(likelihoodfunc, priors, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, num_burnin_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 44\u001b[0m, in \u001b[0;36mMCMC_HMC.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     samples, acceptance_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcceptance rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macceptance_rate\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "Cell \u001b[0;32mIn[23], line 34\u001b[0m, in \u001b[0;36mMCMC_HMC.run_chain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m init_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(init_state)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Running the MCMC chain\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m samples, is_accepted \u001b[38;5;241m=\u001b[39m \u001b[43mtfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_accepted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples, tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mcast(is_accepted, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/sample.py:330\u001b[0m, in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m current_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_state\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    328\u001b[0m     current_state)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_kernel_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m   previous_kernel_results \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;66;03m# It simplifies the logic to use a dummy function here.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   trace_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: ()\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py:443\u001b[0m, in \u001b[0;36mSimpleStepSizeAdaptation.bootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbootstrap_results\u001b[39m(\u001b[38;5;28mself\u001b[39m, init_state):\n\u001b[1;32m    441\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(mcmc_util\u001b[38;5;241m.\u001b[39mmake_name(\n\u001b[1;32m    442\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple_step_size_adaptation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap_results\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 443\u001b[0m     inner_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size_getter_fn(inner_results)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SimpleStepSizeAdaptationResults(\n\u001b[1;32m    446\u001b[0m         inner_results\u001b[38;5;241m=\u001b[39minner_results,\n\u001b[1;32m    447\u001b[0m         step\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32),\n\u001b[1;32m    448\u001b[0m         target_accept_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_accept_prob\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    449\u001b[0m         adaptation_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptation_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    450\u001b[0m         new_step_size\u001b[38;5;241m=\u001b[39mstep_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/hmc.py:533\u001b[0m, in \u001b[0;36mHamiltonianMonteCarlo.bootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbootstrap_results\u001b[39m(\u001b[38;5;28mself\u001b[39m, init_state):\n\u001b[1;32m    532\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates initial `previous_kernel_results` using a supplied `state`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py:273\u001b[0m, in \u001b[0;36mMetropolisHastings.bootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an object with the same type as returned by `one_step`.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    \"target_log_prob\".\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(mcmc_util\u001b[38;5;241m.\u001b[39mmake_name(\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap_results\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 273\u001b[0m   pkr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_target_log_prob(pkr):\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_log_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m must be a member of `inner_kernel` results.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/hmc.py:741\u001b[0m, in \u001b[0;36mUncalibratedHamiltonianMonteCarlo.bootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_gradients_are_stopped:\n\u001b[1;32m    737\u001b[0m   init_state \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mstop_gradient(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m init_state]\n\u001b[1;32m    738\u001b[0m [\n\u001b[1;32m    739\u001b[0m     init_target_log_prob,\n\u001b[1;32m    740\u001b[0m     init_grads_target_log_prob,\n\u001b[0;32m--> 741\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[43mmcmc_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_call_fn_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_log_prob_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m result \u001b[38;5;241m=\u001b[39m UncalibratedHamiltonianMonteCarloKernelResults(\n\u001b[1;32m    743\u001b[0m     log_acceptance_correction\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mzeros_like(init_target_log_prob),\n\u001b[1;32m    744\u001b[0m     target_log_prob\u001b[38;5;241m=\u001b[39minit_target_log_prob,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;66;03m# Allow room for one_step's seed.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     seed\u001b[38;5;241m=\u001b[39msamplers\u001b[38;5;241m.\u001b[39mzeros_seed())\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_parameters_in_results:\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py:297\u001b[0m, in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaybe_call_fn_and_grads\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    295\u001b[0m   fn_arg_list \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(fn_arg_list) \u001b[38;5;28;01mif\u001b[39;00m is_list_like(fn_arg_list)\n\u001b[1;32m    296\u001b[0m                  \u001b[38;5;28;01melse\u001b[39;00m [fn_arg_list])\n\u001b[0;32m--> 297\u001b[0m   result, grads \u001b[38;5;241m=\u001b[39m \u001b[43m_value_and_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_arg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(dtype_util\u001b[38;5;241m.\u001b[39mis_floating(r\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    299\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m (result \u001b[38;5;28;01mif\u001b[39;00m is_list_like(result) \u001b[38;5;28;01melse\u001b[39;00m [result])):  \u001b[38;5;66;03m# pylint: disable=superfluous-parens\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction result must be a `Tensor` with `float` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    301\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`dtype`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py:268\u001b[0m, in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tfp_math_value_and_gradients(fn, fn_arg_list)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_arg_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m, in \u001b[0;36mMCMC_HMC.joint_log_prob\u001b[0;34m(self, *params)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the joint log probability of model and priors.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(params, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Concatenate the parameters into a single array\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m prior_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpriors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m likelihood_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood_function(\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prior_log_prob \u001b[38;5;241m+\u001b[39m likelihood_log_prob\n",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the joint log probability of model and priors.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(params, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Concatenate the parameters into a single array\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m prior_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43mprior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m prior, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriors, params))\n\u001b[1;32m     23\u001b[0m likelihood_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood_function(\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prior_log_prob \u001b[38;5;241m+\u001b[39m likelihood_log_prob\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:1287\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \n\u001b[1;32m   1278\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m      values of type `self.dtype`.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:1269\u001b[0m, in \u001b[0;36mDistribution._call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name, value, kwargs):\n\u001b[1;32m   1268\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_log_prob\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_prob\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob(value, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow_probability/python/distributions/normal.py:186\u001b[0m, in \u001b[0;36mNormal._log_prob\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    184\u001b[0m   scale \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale)\n\u001b[1;32m    185\u001b[0m   log_unnormalized \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msquared_difference(\n\u001b[0;32m--> 186\u001b[0m       \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m/\u001b[39m scale)\n\u001b[1;32m    187\u001b[0m   log_normalization \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(\n\u001b[1;32m    188\u001b[0m       \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m+\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(scale)\n\u001b[1;32m    189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m log_unnormalized \u001b[38;5;241m-\u001b[39m log_normalization\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology2/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py:1412\u001b[0m, in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1410\u001b[0m y_dtype \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_dtype \u001b[38;5;241m!=\u001b[39m y_dtype:\n\u001b[0;32m-> 1412\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`x` and `y` must have the same dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1413\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_dtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_dtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m _TRUEDIV_TABLE[x_dtype]\n",
      "\u001b[0;31mTypeError\u001b[0m: `x` and `y` must have the same dtype, got tf.float64 != tf.float32."
     ]
    }
   ],
   "source": [
    "mcmc = MCMC_HMC(likelihoodfunc, priors, num_samples=10, num_chains=4, step_size=0.1, num_burnin_steps=10)\n",
    "samples = mcmc.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.41.2)\n",
      "Requirement already satisfied: rich in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/henrybae/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.13.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.3,>=1.22.4 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from scipy) (1.26.4)\n",
      "Downloading scipy-1.13.0-cp310-cp310-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/henrybae/miniconda3/envs/cosmology2/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.2-cp310-cp310-macosx_12_0_arm64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 threadpoolctl-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
