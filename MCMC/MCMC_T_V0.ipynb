{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[982.32562024 927.57538209 875.41964977 ...  36.22063115  36.11447954\n",
      "  36.00921749]\n",
      "[ 2.75474425  3.09469103  2.90353789 ... -1.26516941 -1.27129668\n",
      " -1.27752765]\n",
      "[0.03586869 0.04609061 0.04003475 ... 1.56565523 1.56519372 1.56468134]\n"
     ]
    }
   ],
   "source": [
    "import camb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def calculate_power_spectra(params, lensed=True):\n",
    "    # Set up a new set of parameters for CAMB\n",
    "    pars = camb.set_params(**params)\n",
    "    # Calculate results for these parameters\n",
    "    results = camb.get_results(pars)\n",
    "    # Get dictionary of CAMB power spectra\n",
    "    powers = results.get_cmb_power_spectra(pars, CMB_unit='muK')\n",
    "    # Choose the appropriate power spectrum\n",
    "    if lensed:\n",
    "        cl = powers['total']\n",
    "    else:\n",
    "        cl = powers['unlensed_scalar']\n",
    "    # Cut out the first 2 elements of the power spectra, which are zero\n",
    "    cl_cut = cl[2:]\n",
    "    # Get the TT, TE, and EE power spectra\n",
    "    cl_tt = cl_cut[:, 0]\n",
    "    cl_te = cl_cut[:, 3]\n",
    "    cl_ee = cl_cut[:, 1]\n",
    "    return cl_tt, cl_te, cl_ee\n",
    "\n",
    "params = {\n",
    "    # Parameters that are part of the proposal distribution:\n",
    "    'ombh2': 0.025,                # Baryon density parameter\n",
    "    'omch2': 0.122,                # Cold dark matter density parameter\n",
    "    'cosmomc_theta': 1.04109/100,       # Theta_MC - need to be transformed\n",
    "    'tau': 0.06,                   # Optical depth to reionization\n",
    "    'ns': 0.965,                   # Scalar spectral index\n",
    "    'As': 2.0e-9,# the scalar amplitude, need to be transformed for proposal distribution\n",
    "\n",
    "    # Fixed parameters:\n",
    "    #'H0': 69.5,                    # Hubble constant in km/s/Mpc (Fixed)\n",
    "    'mnu': 0.06,                   # Sum of neutrino masses in eV (Fixed)\n",
    "    'omk': 0,                      # Curvature density parameter, flat universe (Fixed)\n",
    "    'halofit_version': 'mead',     # Non-linear matter power spectrum model version (Fixed)\n",
    "    'lmax': 2800                   # Maximum multipole number for calculations (Fixed)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "cl_tt, cl_te, cl_ee = calculate_power_spectra(params, lensed=True)\n",
    "print(cl_tt)\n",
    "print(cl_te)\n",
    "print(cl_ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1058.7842310098813"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import likelihood\n",
    "from likelihood import PlanckLitePy\n",
    "\n",
    "likelihood_function = likelihood.PlanckLitePy()\n",
    "\n",
    "likelihood_function.loglike(cl_tt, cl_te, cl_ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_params_and_calculate_spectra(array):\n",
    "    array = array.copy()  # Create a copy of the array\n",
    "    # Modify the third and sixth elements of the array\n",
    "    array[2] /= 100\n",
    "    array[5] = np.exp(array[5]) / 1e10\n",
    "\n",
    "    # Set the parameters for the proposal distribution\n",
    "    params = {\n",
    "        'ombh2': array[0],\n",
    "        'omch2': array[1],\n",
    "        'cosmomc_theta': array[2],\n",
    "        'tau': array[3],\n",
    "        'ns': array[4],\n",
    "        'As': array[5],\n",
    "\n",
    "        \n",
    "        'mnu': 0.06,\n",
    "        'omk': 0,\n",
    "        'halofit_version': 'mead',\n",
    "        'lmax': 2800\n",
    "    }\n",
    "\n",
    "    # Call the calculate_power_spectra function and return the result\n",
    "    return calculate_power_spectra(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_distribution(current_state):\n",
    "    step_sizes = np.array([\n",
    "        np.sqrt(0.0001**2),  # ombh2\n",
    "        np.sqrt(0.001**2),   # omch2\n",
    "        np.sqrt(0.0004**2),  # theta_MC_100\n",
    "        np.sqrt(0.006**2),   # tau\n",
    "        np.sqrt(0.004**2),   # ns\n",
    "        np.sqrt(0.001**2)    # log(10^10 As)\n",
    "    ])\n",
    "    proposal_step = np.random.normal(0, step_sizes)\n",
    "    return current_state + proposal_step\n",
    "\n",
    "\n",
    "def generate_initial_state():\n",
    "    pass\n",
    "\n",
    "\n",
    "def proposal_distribution_2(current_state):\n",
    "    step_sizes = np.array([\n",
    "        np.sqrt(0.0001**2),  # ombh2\n",
    "        np.sqrt(0.001**2),   # omch2\n",
    "        np.sqrt(0.0004**2),  # theta_MC_100\n",
    "        np.sqrt(0.006**2),   # tau\n",
    "        np.sqrt(0.004**2),   # ns\n",
    "        np.sqrt(0.001**2)    # log(10^10 As)\n",
    "    ])\n",
    "    proposal_step = np.random.normal(0, step_sizes)\n",
    "    return current_state + proposal_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "import os\n",
    "import time\n",
    "\n",
    "class MCMC_MH:\n",
    "    def __init__(self, likelihood, proposal_distribution, initial_state, num_samples, num_chains, stepsize=0.5, burnin_ratio=0.05, resume=False):\n",
    "        self.likelihood = likelihood\n",
    "        self.proposal_distribution = proposal_distribution\n",
    "        self.curr_state = [initial_state]*num_chains\n",
    "        self.curr_likeli = [likelihood.loglike(*process_params_and_calculate_spectra(initial_state))]*num_chains\n",
    "        self.num_samples = num_samples\n",
    "        self.num_chains = num_chains\n",
    "        self.stepsize = stepsize\n",
    "        self.burnin = int(burnin_ratio * num_samples)  # calculate burn-in steps as 5% of total samples\n",
    "        self.samples = [[] for _ in range(num_chains)]\n",
    "        self.checkpoint_interval = 5\n",
    "        self.resume = resume\n",
    "\n",
    "        if resume:\n",
    "            self.load_checkpoint()\n",
    "        elif os.path.exists('./checkpoints') and os.listdir('./checkpoints'):\n",
    "            raise ValueError(\"The './checkpoints' directory should be empty when starting a new run.\")\n",
    "\n",
    "    def save_checkpoint(self, iteration, burn_in=False):\n",
    "        if not os.path.exists('./checkpoints'):\n",
    "            os.makedirs('./checkpoints')\n",
    "        filename = f'./checkpoints/checkpoint_{\"burnin\" if burn_in else \"production\"}.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump((self.curr_state, self.samples), f)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        checkpoint_files = [f for f in os.listdir('./checkpoints') if f.endswith('.pkl')]\n",
    "        if not checkpoint_files:\n",
    "            raise ValueError(\"No checkpoints found to resume from.\")\n",
    "        latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
    "        with open(f'./checkpoints/{latest_checkpoint}', 'rb') as f:\n",
    "            self.curr_state, self.samples = pickle.load(f)\n",
    "\n",
    "    def burn_in(self):\n",
    "        start_time = time.time()\n",
    "        if self.resume:\n",
    "            self.load_checkpoint()\n",
    "\n",
    "        for i in range(self.burnin):\n",
    "            for j in range(self.num_chains):\n",
    "                self.mcmc_updater(j)\n",
    "            if (i + 1) % self.checkpoint_interval == 0:\n",
    "                self.save_checkpoint(i + 1, burn_in=True)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Completed {i+1} burn-in steps in {elapsed_time} seconds\")\n",
    "\n",
    "    def mcmc_updater(self, chain_index):\n",
    "        proposal_state = self.proposal_distribution(self.curr_state[chain_index])\n",
    "\n",
    "        prop_loglikeli = self.likelihood.loglike(*process_params_and_calculate_spectra(proposal_state))\n",
    "        print(prop_loglikeli)\n",
    "        accept_crit = prop_loglikeli - self.curr_likeli[chain_index]\n",
    "        accept_threshold = np.log(np.random.uniform(0, 1))\n",
    "\n",
    "        if accept_crit > accept_threshold:\n",
    "            print(\"Accepted\")\n",
    "            self.curr_state[chain_index], self.curr_likeli[chain_index] = proposal_state, prop_loglikeli\n",
    "        else:\n",
    "            print(\"Rejected\")\n",
    "\n",
    "        return self.curr_state[chain_index], self.curr_likeli[chain_index]\n",
    "\n",
    "    def metropolis_hastings(self):\n",
    "        start_time = time.time()\n",
    "        self.burn_in()  # perform burn-in before production run\n",
    "\n",
    "        if self.resume:\n",
    "            self.load_checkpoint()\n",
    "\n",
    "        for i in range(self.num_samples):\n",
    "            for j in range(self.num_chains):\n",
    "                self.curr_state[j], self.curr_likeli[j] = self.mcmc_updater(j)\n",
    "                self.samples[j].append(self.curr_state[j])\n",
    "            if (i + 1) % self.checkpoint_interval == 0:\n",
    "                self.save_checkpoint(i + 1)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Completed {i+1} steps in {elapsed_time} seconds\")\n",
    "            if (i + 1) % 1 == 0:\n",
    "                self.calculate_convergence()\n",
    "\n",
    "        return self.samples\n",
    "\n",
    "    def calculate_convergence(self):\n",
    "        # Calculate the mean of each chain\n",
    "        chain_means = [np.mean(chain) for chain in self.samples]\n",
    "\n",
    "        # Calculate the variance of each chain\n",
    "        chain_vars = [np.var(chain, ddof=1) for chain in self.samples]\n",
    "\n",
    "        # Calculate the mean of all samples\n",
    "        grand_mean = np.mean(chain_means)\n",
    "\n",
    "        # Calculate B, the between-chain variance\n",
    "        B = self.num_samples / (self.num_chains - 1) * np.sum((chain_means - grand_mean) ** 2)\n",
    "\n",
    "        # Calculate W, the within-chain variance\n",
    "        W = np.mean(chain_vars)\n",
    "\n",
    "        # Calculate the variance estimate for the pooled chains\n",
    "        var_estimate = (1 - 1 / self.num_samples) * W + 1 / self.num_samples * B\n",
    "\n",
    "        # Calculate the potential scale reduction factor (R-1 statistic)\n",
    "        R_minus_one = (var_estimate - W) / var_estimate\n",
    "\n",
    "        print(f'R-1 statistic: {R_minus_one}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = np.array([0.025, 0.122, 1.04109, 0.06, 0.965, np.log(2.0e-9*1e10)])\n",
    "\n",
    "mcmc = MCMC_MH(likelihood_function, proposal_distribution, initial_state, 1000, stepsize=0.5, burnin_ratio=0.0, resume=False, num_chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'MCMC_MH' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'MCMC_MH' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'MCMC_MH' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/henrybae/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'MCMC_MH' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetropolis_hastings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 81\u001b[0m, in \u001b[0;36mMCMC_MH.metropolis_hastings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples):\n\u001b[0;32m---> 81\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcmc_updater\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_state[j], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_likeli[j] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmology/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mcmc.metropolis_hastings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
